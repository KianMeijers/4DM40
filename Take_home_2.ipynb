{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0fd6301-c468-4403-9559-057b21ed0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "\n",
    "#--- Functions ---#\n",
    "#-- Cleaning up source data --#\n",
    "def clean_sd(path,ec):\n",
    "    cd = []\n",
    "    with open(path,'r') as f:\n",
    "        for line in f:\n",
    "            columns = line.strip().split('\\t')\n",
    "            if len(columns)<ec:\n",
    "                columns += [''] * (ec - len(columns))\n",
    "            elif len(columns)<ec:\n",
    "                columns = columns[:2] + [' '.join(columns[2:])]\n",
    "            \n",
    "            cd.append(columns)\n",
    "\n",
    "    return cd\n",
    "\n",
    "def complete_sd(path,cn):\n",
    "    \"\"\"\n",
    "    Completes source data by adding arrival events to corresponding workstations\n",
    "    \"\"\"\n",
    "    sd = []\n",
    "    WS = [\"W1\",\"W2\",\"W3\"]\n",
    "    with open(path,'r') as f:\n",
    "        for line in f:\n",
    "            columns = line.strip().split('\\t')\n",
    "            #Translate creation event into arrival at WS 1\n",
    "            if columns[2] == \"Created\":\n",
    "                columns[2] = WS[0]\n",
    "                columns.append(\"A\")\n",
    "                sd.append(columns)\n",
    "            \n",
    "            elif columns[3] == \"D\":\n",
    "                sd.append(columns)\n",
    "                W_departing = WS.index(columns[2])\n",
    "\n",
    "                if W_departing < 2:\n",
    "                    new_entry = [None]*4\n",
    "                    new_entry[:2] = columns[:2]\n",
    "                    new_entry[2:] = [WS[W_departing+1],\"A\"]\n",
    "                    sd.append(new_entry)\n",
    "    \n",
    "    sd_c = pd.DataFrame(sd,columns=cn)\n",
    "    sd_c[\"time\"] = pd.to_numeric(sd_c[\"time\"])\n",
    "    return sd_c\n",
    "\n",
    "def split_sd(sd_c,ws):\n",
    "    \"\"\"\n",
    "    Devide completed source data per workstation\n",
    "    \"\"\"\n",
    "    sd_s = sd_c.loc[sd_c.workstation == ws].copy()\n",
    "    sd_s = sd_s.drop(\"workstation\",axis=1)\n",
    "    return sd_s\n",
    "\n",
    "def get_arrival(sd_c,hb):\n",
    "    \"\"\"\n",
    "    Determines the mean, standard deviation and coefficient of covariance for lots and batches (if applicable)\n",
    "    Returns the batch structure if applicable\n",
    "    \"\"\"\n",
    "    # select arrival data and determine the difference between arrivals\n",
    "    Lot_dT = sd_c[sd_c['event'] == 'A']['time'].diff()\n",
    "    # Determine mean, standard deviation and coefficient of covariance\n",
    "    Lot_mean = Lot_dT.mean()\n",
    "    Lot_std = Lot_dT.std()\n",
    "    Lot_CoV = Lot_std/Lot_mean\n",
    "    \n",
    "    # handle as batch\n",
    "    if hb:\n",
    "        # build batch data structure\n",
    "        Batch = build_batch_view(sd_c)\n",
    "        # select arrival data and determine the difference between arrivals\n",
    "        Batch_dT = Batch[Batch['event'] == 'A']['time'].diff()\n",
    "        Batch_mean = Batch_dT.mean()\n",
    "        Batch_std = Batch_dT.std()\n",
    "        Batch_CoV = Batch_std/Batch_mean\n",
    "    else:\n",
    "        Batch = None\n",
    "        Batch_mean = None\n",
    "        Batch_std = None\n",
    "        Batch_CoV = None\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        \"Workstation\": [\"Batch\", \"Lot\"],\n",
    "        \"Mean\": [Batch_mean, Lot_mean],\n",
    "        \"Std\": [Batch_std, Lot_std],\n",
    "        \"CoV\": [Batch_CoV, Lot_CoV]})\n",
    "\n",
    "    # print(result)\n",
    "    return result, Batch\n",
    "\n",
    "def get_distribution(EPT_r):\n",
    "    \"\"\"\n",
    "    Determines the EPT mean, standard deviation and coefficient of variance\n",
    "    Additionally the amount of realizations is determined for reporting purpouses\n",
    "    \"\"\"\n",
    "    # Group data by WIP levels and determine the count, mean and standard deviation for each WIP level\n",
    "    EPT_distribution = EPT_r.groupby('sw')['EPT'].agg(['count','mean','std'])\n",
    "    # Determine the covariance: standard deviation / mean\n",
    "    EPT_distribution['CoV'] = EPT_distribution['std'] / EPT_distribution['mean']\n",
    "\n",
    "    # Group data by Number of lots in the buffer and determine the count, mean and standard deviation for each WIP level\n",
    "    OT_distribution = EPT_r.groupby('aw')['k'].agg(['count','mean','std'])\n",
    "    # Determine the covariance: standard deviation / mean\n",
    "    OT_distribution['CoV'] = OT_distribution['std'] / OT_distribution['mean']\n",
    "    \n",
    "    #print(EPT_distribution)\n",
    "    #print(OT_distribution)\n",
    "    return EPT_distribution, OT_distribution\n",
    "\n",
    "#-- EPT calculations --#\n",
    "def get_ept_data(df):\n",
    "    def detOvert(xs, i):\n",
    "        ys = []\n",
    "        while xs:\n",
    "            j, aw = xs[0]       # head(xs)\n",
    "            xs = xs[1:]         # tail(xs)\n",
    "            if j < i:\n",
    "                ys.append((j, aw))\n",
    "            elif j == i:\n",
    "                return ys + xs, len(ys), aw \n",
    "        raise ValueError(f\"Lot {i} not found in system\")\n",
    "\n",
    "    initial_wip = 0\n",
    "    non_tracked_lots = list()  # lots not tracked by the system\n",
    "\n",
    "    # count initial WIP \n",
    "    for lot in df.lot.unique():\n",
    "        if not df.loc[df.lot == lot, \"event\"].str.contains(\"A\").any():\n",
    "            initial_wip += 1\n",
    "            non_tracked_lots.append(lot)\n",
    "\n",
    "    # prefil xs with initial WIP\n",
    "    xs = [(lot, initial_wip) for lot in non_tracked_lots] #state of system,\n",
    "    s, sw = None, None          #  EPT start time, WIP at start\n",
    "    records = []                        # output rows\n",
    "\n",
    "    for τ, i, ev, *_ in df.itertuples(index=False, name=None):\n",
    "\n",
    "        if ev.upper() == \"A\":           \n",
    "            if not xs:                  # empty system -> new EPT\n",
    "                s, sw = τ, 1\n",
    "            xs.append((i, len(xs)))     # len(xs) is WIP before this arrival\n",
    "\n",
    "        elif ev.upper() == \"D\":         \n",
    "\n",
    "            xs, k, aw = detOvert(xs, i)\n",
    "\n",
    "            if i not in non_tracked_lots:\n",
    "                # determine EPT\n",
    "                ept = τ - s\n",
    "                # save record\n",
    "                records.append(dict(lot=i, EPT=ept, sw=sw, k=k, aw=aw))\n",
    "\n",
    "            # start a new EPT if system still contains lots\n",
    "            if xs:\n",
    "                s, sw = τ, len(xs)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown event type '{ev}'\")\n",
    "    results = pd.DataFrame(records)\n",
    "    return results\n",
    "\n",
    "def build_batch_view(df: pd.DataFrame):\n",
    "    # Simultaneous departures are a batch\n",
    "    dep = df[df.event.str.upper() == \"D\"].copy()\n",
    "    dep[\"group\"] = dep.groupby(\"time\").ngroup()\n",
    "\n",
    "    batches = dep.groupby(\"group\").filter(lambda g: len(g) > 0).copy()\n",
    "\n",
    "    # create a batch id for each group\n",
    "    group2virtual = {g: f\"B{n}\" for n, g in enumerate(sorted(batches.group.unique()))}\n",
    "    batches[\"virtual\"] = batches.group.map(group2virtual)\n",
    "\n",
    "    lot2batch  = dict(zip(batches.lot, batches.virtual))\n",
    "\n",
    "    # arrival = latest arrival of any member in the batch\n",
    "    arrivals = (\n",
    "        df[df.event.str.upper() == \"A\"]\n",
    "          .loc[df.lot.isin(lot2batch)]                 # only batched lots\n",
    "          .assign(virtual=lambda d: d.lot.map(lot2batch))\n",
    "          .groupby(\"virtual\", as_index=False)\n",
    "          .agg(time=(\"time\", \"max\"),\n",
    "               lot_ids=(\"lot\", lambda x: list(x)))     # collect ids\n",
    "          .assign(event=\"A\", lot=lambda d: d.virtual)  # rename columns\n",
    "          .drop(columns=\"virtual\")\n",
    "    )\n",
    "\n",
    "    # departure = common departure time \n",
    "    departures = (\n",
    "        batches.groupby(\"virtual\", as_index=False)\n",
    "               .agg(time=(\"time\", \"first\"),\n",
    "                    lot_ids=(\"lot\", lambda x: list(x)))\n",
    "               .assign(event=\"D\", lot=lambda d: d.virtual)\n",
    "               .drop(columns=\"virtual\")\n",
    "    )\n",
    "\n",
    "    drop_lots = set(lot2batch)                       # originals replaced by batch rows\n",
    "\n",
    "    df_batch = (\n",
    "        pd.concat([df, arrivals, departures], ignore_index=True)\n",
    "          .loc[lambda d: ~d[\"lot\"].isin(drop_lots)]  \n",
    "          .sort_values(\"time\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return df_batch\n",
    "\n",
    "\n",
    "#--- Take Home solver ---#\n",
    "#-- variables --#\n",
    "# source data\n",
    "sd_path = 'group07.txt'\n",
    "expected_nr_columns = 4\n",
    "column_names = ['time', 'lot', \"workstation\", 'event']\n",
    "\n",
    "#-- Load assignment data --#\n",
    "sd_completed = complete_sd(sd_path,column_names)\n",
    "sd_W1 = split_sd(sd_completed,\"W1\")\n",
    "sd_W2 = split_sd(sd_completed,\"W2\")\n",
    "sd_W3 = split_sd(sd_completed,\"W3\")\n",
    "\n",
    "Arival_W1, _ = get_arrival(sd_W1,False)\n",
    "Arival_W2, _ = get_arrival(sd_W2,False)\n",
    "Arival_W3, _ = get_arrival(sd_W3,False)\n",
    "Arival_W2, Batch_W2 = get_arrival(sd_W2,True)\n",
    "\n",
    "EPT_W1r = get_ept_data(sd_W1)\n",
    "EPT_W2r = get_ept_data(Batch_W2)\n",
    "EPT_W3r = get_ept_data(sd_W3)\n",
    "\n",
    "[EPTd_W1, OTd_W1] = get_distribution(EPT_W1r)\n",
    "[EPTd_W2, OTd_W2] = get_distribution(EPT_W2r)\n",
    "[EPTd_W3, OTd_W3] = get_distribution(EPT_W3r)\n",
    "\n",
    "sd_completed = complete_sd(sd_path,column_names)\n",
    "sd_W1 = split_sd(sd_completed,\"W1\")\n",
    "Arival_W1, _ = get_arrival(sd_W1,False)\n",
    "EPT_W1r = get_ept_data(sd_W1)\n",
    "[EPTd_W1, OTd_W1] = get_distribution(EPT_W1r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0539e7e-10b4-45e1-967b-ea9ba35bbc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           lot  EPT  sw  k  aw\n",
      "0     lot00994   76   1  0   0\n",
      "1     lot00995   30   2  0   1\n",
      "2     lot00997   80   1  1   1\n",
      "3     lot00996  179   1  0   2\n",
      "4     lot00998   46   3  0   1\n",
      "...        ...  ...  .. ..  ..\n",
      "9991  lot10985  125   2  1   3\n",
      "9992  lot10983   18   4  0   1\n",
      "9993  lot10987   13   3  0   2\n",
      "9994  lot10989   29   2  1   4\n",
      "9995  lot10988   11   1  0   3\n",
      "\n",
      "[9996 rows x 5 columns]\n",
      "      lot  EPT  sw  k  aw\n",
      "0      B1  631   1  0   0\n",
      "1      B2  548   1  0   0\n",
      "2      B3  510   1  0   0\n",
      "3      B4  596   1  0   0\n",
      "4      B5  527   1  0   0\n",
      "..    ...  ...  .. ..  ..\n",
      "993  B994  604   1  0   0\n",
      "994  B995  605   1  0   1\n",
      "995  B996  549   1  0   1\n",
      "996  B997  547   1  0   0\n",
      "997  B998  444   1  0   0\n",
      "\n",
      "[998 rows x 5 columns]\n",
      "           lot  EPT  sw  k  aw\n",
      "0     lot00978   27   1  0   0\n",
      "1     lot00983   31   9  0   1\n",
      "2     lot00984   41   8  0   2\n",
      "3     lot00982   28   7  0   3\n",
      "4     lot00985   23   6  0   4\n",
      "...        ...  ...  .. ..  ..\n",
      "9985  lot10968   29   5  0   5\n",
      "9986  lot10969   26   4  0   6\n",
      "9987  lot10966   29   3  0   7\n",
      "9988  lot10970   11   2  0   8\n",
      "9989  lot10972   29   1  0   9\n",
      "\n",
      "[9990 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(EPT_W1r)\n",
    "print(EPT_W2r)\n",
    "print(EPT_W3r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f02d933-06b0-4e5d-a384-475b88c33ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPTs (min) and c_e^2:\n",
      "  W1_wip3plus: 47.56\n",
      "  W2_all: 554.64\n",
      "  W3_all: 36.86\n",
      "  c_e2_W1: 1.00\n",
      "  c_e2_W2: 0.01\n",
      "  c_e2_W3: 0.99\n",
      "  W2_batch_size: 9.91 lots/batch\n",
      "Delays and Fractions:\n",
      "  W1: 1 periods, fraction = 0.1321\n",
      "  W2: 2 periods, fraction = 0.5407\n",
      "  W3: 1 periods, fraction = 0.1024\n",
      "State-Space:\n",
      "States: ['x1', 'x2', 'x3', 'u2(k-1)', 'u3(k-1)', 'u3(k-2)']\n",
      "Controls: ['u1', 'u2', 'u3']\n",
      "Output: ['y']\n",
      "A:\n",
      " [[1.     0.     0.     0.     0.     0.    ]\n",
      " [0.     1.     0.     0.1321 0.     0.    ]\n",
      " [0.     0.     1.     0.     0.     0.5407]\n",
      " [0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     0.     1.     1.    ]]\n",
      "B:\n",
      " [[ 1. -1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  0.]]\n",
      "C:\n",
      " [[0.     0.     0.     0.     0.1024 0.    ]]\n",
      "Constraints:\n",
      "  W1: 0 <= u_W1 <= min(7.5700, 1.0028 * u_W1 * 0.7926 / (1.0028 + x_W1 * 0.7926))\n",
      "  W2: 0 <= u_W2 <= min(6.4347, 1.8005 * u_W2 * 9.2439 / (1.8005 + x_W2 * 9.2439))\n",
      "        u_W2 <= x_W1\n",
      "  W3: 0 <= u_W3 <= min(9.7669, 2.0676 * u_W3 * 0.6143 / (2.0676 + x_W3 * 0.6143))\n",
      "        u_W3 <= x_W2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def compute_ept_data(EPT_W1r, EPT_W2r, EPT_W3r, Batch_W2):\n",
    "    return {\n",
    "        'W1_wip3plus': EPT_W1r[EPT_W1r['aw'] >= 3]['EPT'].mean(),\n",
    "        'W2_all': EPT_W2r['EPT'].mean(),\n",
    "        'W3_all': EPT_W3r['EPT'].mean(),\n",
    "        'c_e2_W1': EPT_W1r[EPT_W1r['aw'] >= 3]['EPT'].var() / (EPT_W1r[EPT_W1r['aw'] >= 3]['EPT'].mean() ** 2),\n",
    "        'c_e2_W2': EPT_W2r['EPT'].var() / (EPT_W2r['EPT'].mean() ** 2),\n",
    "        'c_e2_W3': EPT_W3r['EPT'].var() / (EPT_W3r['EPT'].mean() ** 2),\n",
    "        'W2_batch_size': len(Batch_W2['lot_ids'].explode()) / len(Batch_W2)\n",
    "    }\n",
    "\n",
    "def build_state_space_model(ept_data, sampling_time=360):\n",
    "    \"\"\"State-space model with delays and constraints. Follows the way they did it in Exercises 2 and 3.\"\"\"\n",
    "    delays = {ws: math.ceil(ept_data[f'{ws}_all' if ws != 'W1' else 'W1_wip3plus'] / sampling_time) \n",
    "              for ws in ['W1', 'W2', 'W3']}\n",
    "#------------\n",
    "    # Fractional effects for delays. ChatGPT added this and I am unsure if it is correct.\n",
    "    fractions = {ws: min((ept_data[f'{ws}_all' if ws != 'W1' else 'W1_wip3plus'] % sampling_time) / sampling_time, 1.0) \n",
    "                 if delays[ws] > 0 else 1.0 for ws in ['W1', 'W2', 'W3']}\n",
    "#------------\n",
    "    d1, d2 = delays['W1'], delays['W2']\n",
    "    state_dim = 3 + d1 + d2\n",
    "    A = np.eye(state_dim)\n",
    "    B = np.zeros((state_dim, 3))\n",
    "    C = np.zeros((1, state_dim))\n",
    "\n",
    "#------------\n",
    "# Not sure if correct in general\n",
    "\n",
    "    # WIP dynamics\n",
    "    B[0, 0], B[0, 1] = 1, -1  # x1: u1 - u2\n",
    "    B[1, 2] = -1              # x2: -u3\n",
    "    A[1, 3 + d1 - 1] = fractions['W1']  # x2: u2(k-d1)\n",
    "    A[2, 3 + d1 + d2 - 1] = fractions['W2']  # x3: u3(k-d2)\n",
    "\n",
    "    # Delay states\n",
    "    for i in range(d1 - 1):\n",
    "        A[3 + i + 1, 3 + i] = 1\n",
    "    for i in range(d2 - 1):\n",
    "        A[3 + d1 + i + 1, 3 + d1 + i] = 1\n",
    "    B[3, 1] = 1\n",
    "    B[3 + d1, 2] = 1\n",
    "#------------\n",
    "#------------\n",
    "    # Output: y = u3(k-d3)\n",
    "    if delays['W3'] > 0:\n",
    "        C[0, 3 + d1 + delays['W3'] - 1] = fractions['W3']\n",
    "#------------\n",
    "\n",
    "    # Constraints (Kingman's formula) -> Check slides for formula\n",
    "    c_a2 = {'W1': 1.007654, 'W2': 0.352636, 'W3': 3.145749} # Taken from Arival_W1 in Take_home_1\n",
    "    constraints = {}\n",
    "    for ws, ept_key in [('W1', 'W1_wip3plus'), ('W2', 'W2_all'), ('W3', 'W3_all')]:\n",
    "        ept = ept_data[ept_key]\n",
    "        u_max = sampling_time / ept\n",
    "        c = (c_a2[ws] + ept_data[f'c_e2_{ws}']) / 2\n",
    "        t_e = ept / 60\n",
    "        scale = ept_data['W2_batch_size'] if ws == 'W2' else 1.0 # Only prints for workstation 2\n",
    "        constraints[ws] = {'u_max': u_max * scale, 'c': c * scale, 't_e': t_e}\n",
    "    \n",
    "    return {\n",
    "        'A': A, 'B': B, 'C': C,\n",
    "        'states': ['x1', 'x2', 'x3'] + [f'u2(k-{i+1})' for i in range(d1)] + [f'u3(k-{i+1})' for i in range(d2)],\n",
    "        'controls': ['u1', 'u2', 'u3'],\n",
    "        'output': ['y'],\n",
    "        'delays': delays,\n",
    "        'fractions': fractions,\n",
    "        'constraints': constraints\n",
    "    }\n",
    "\n",
    "def print_model(model, ept_data):\n",
    "    \"\"\"Print model summary for sanity check.\"\"\"\n",
    "    print(\"EPTs (min) and c_e^2:\")\n",
    "    for k, v in ept_data.items():\n",
    "        print(f\"  {k}: {v:.2f}{' lots/batch' if k == 'W2_batch_size' else ''}\")\n",
    "    \n",
    "    print(\"Delays and Fractions:\")\n",
    "    for ws in model['delays']:\n",
    "        print(f\"  {ws}: {model['delays'][ws]} periods, fraction = {model['fractions'][ws]:.4f}\")\n",
    "    \n",
    "    print(\"State-Space:\")\n",
    "    print(\"States:\", model['states'])\n",
    "    print(\"Controls:\", model['controls'])\n",
    "    print(\"Output:\", model['output'])\n",
    "    print(\"A:\\n\", np.round(model['A'], 4))\n",
    "    print(\"B:\\n\", np.round(model['B'], 4))\n",
    "    print(\"C:\\n\", np.round(model['C'], 4))\n",
    "    \n",
    "    print(\"Constraints:\")\n",
    "    for ws, c in model['constraints'].items():\n",
    "        print(f\"  {ws}: 0 <= u_{ws} <= min({c['u_max']:.4f}, {c['c']:.4f} * u_{ws} * {c['t_e']:.4f} / ({c['c']:.4f} + x_{ws} * {c['t_e']:.4f}))\")\n",
    "        if ws != 'W1':\n",
    "            print(f\"        u_{ws} <= x_{'W1' if ws == 'W2' else 'W2'}\")\n",
    "\n",
    "# Execute and print everything\n",
    "ept_data = compute_ept_data(EPT_W1r, EPT_W2r, EPT_W3r, Batch_W2)\n",
    "model = build_state_space_model(ept_data)\n",
    "print_model(model, ept_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cc58652-0ff3-4c50-839f-bed0392810c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_constraints_and_tangents(ept_data, model):\n",
    "    \"\"\"Plot WIP-dependent constraints and their tangent approximations at specified utilizations for question 2.\"\"\"\n",
    "    constraints = model['constraints']\n",
    "    utilizations = [0, 0.35, 0.7, 0.8, 0.9, 1.0] # These are provided in the assignment.\n",
    "    \n",
    "    for ws in ['W1', 'W2', 'W3']:\n",
    "        c = constraints[ws]['c']\n",
    "        t_e = constraints[ws]['t_e']\n",
    "        u_max = constraints[ws]['u_max']\n",
    "        \n",
    "        # WIP range for plotting\n",
    "        x = np.linspace(0, 20, 1000)  # Guess this is a reasonable WIP range\n",
    "        u = np.minimum(x / (c * t_e + x * t_e), u_max)\n",
    "        \n",
    "        # Plot constraint curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(x, u, 'b-', label=f'{ws} Constraint')\n",
    "        \n",
    "        # Compute tangents\n",
    "        for rho in utilizations:\n",
    "            u_i = rho / t_e\n",
    "            if u_i >= u_max:\n",
    "                u_i = u_max\n",
    "                rho = u_i * t_e  # Adjust rho if capped\n",
    "            x_i = (c * u_i * t_e) / (1 - u_i * t_e) if u_i * t_e < 1 else 1 # Goes to inf if not smaller than 1\n",
    "            \n",
    "            # Derivative du/dx\n",
    "            du_dx = c * t_e / (c * t_e + x_i * t_e) ** 2\n",
    "            \n",
    "            # Tangent line\n",
    "            u_tangent = u_i + du_dx * (x - x_i)\n",
    "            u_tangent = np.minimum(u_tangent, u_max)  # Cap at u_max. Otherwise the bounds of the plot are messy. Limiting plot range didn't work for some reason, so temp fix\n",
    "            \n",
    "            # Plot tangent\n",
    "            plt.plot(x, u_tangent, '--', label=f'ρ={rho}')\n",
    "\n",
    "        plt.title(f'WIP-Dependent Constraint and Tangents for {ws}')\n",
    "        plt.xlabel(f'WIP (x_{ws})')\n",
    "        plt.ylabel(f'Input Rate (u_{ws})')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(f'constraint_{ws}.png')\n",
    "        plt.close()\n",
    "\n",
    "plot_constraints_and_tangents(ept_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d52d8-3865-4457-94d5-79559ed31ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:4DM40_env] *",
   "language": "python",
   "name": "conda-env-4DM40_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
